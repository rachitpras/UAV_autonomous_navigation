---
layout: post
title:  "A Remote ID based autonomous operations framework for small UAS"
date:   2021-11-23 10:26:20 -0500
categories: Project explanation
---

As per Federal Aviation Agency's (FAA) definition, **remote ID is the ability of a drone in flight to provide identification and location information that can be received by other parties**. As per the FAA, remote ID will play an important role in the integration of autonomous Unmanned Aerial Systems (UAS) operations in the National Aerospace System. The final rule on remote ID will require most drones operating in US airspace to have remote ID capability. Remote ID will provide information about drones in flight, such as the identity, location, and altitude of the drone and its control station or take-off location. Authorized individuals from public safety organizations may request identity of the drone's owner from the FAA. More details on this can be found from [FAA's website](https://www.faa.gov/uas/getting_started/remote_id/).

# A collision-free, autonomous navigation framework for small UAS using remote ID

Large autonomous systems, such as self driving cars, deploy an array of sensors such as cameras, LIDAR, RADAR, etc for perception and SLAM. However, for small UAS, these sensors can be bulky and can substantially reduced its payload capacity. Relying on a one or fewer sensors can reduce reliability. For example, relying just on the camera for obstacle prediciton and tracking, in a sparse but highly dynamic environment is error prone. Keeping this in mind, in our National Science Foundation (NSF) sponsored project, we have developed a collision-free, autonomous navigation framework which uses the Remote ID concept to carry out tasks such as environment perception and obstacle tracking. The developed framework can be used as the primary or support stack. A schematic of the framework is given below. 

<img src="https://github.com/rachitpras/UAV_autonomous_navigation/blob/main/images/framework_schematic.JPG" alt="Schematic for the UAS navigation framework" width="800"/> 
<!--- ![Schematic for UAS navigation framework](/images/framework_schematic.JPG) -->

The framework consists of different modules performing different roles. The **remote ID communication module** communicates with the remote ID server to pass on its information and request information on the environment. For now, this is being done over Wi-Fi using HTTPS. More information regarding this module can be found [**here**](https://rachitpras.github.io/UAV_autonomous_navigation/project/explanation/2021/11/26/Rest-API-based-Remote-ID-communication-module.html). Based on the location of the ego-vehicle, the remote ID server returns information such as location of static obstacles in the neighborhood, trajectory history of nearby dynamic obstacles, etc. is then passed on to the downstream modules. The trajectory history of nearby dynamic obstacles is used by the **target tracking module** to predict their future trajectory. In our project, we have relied on data-driven machine learning approaches for this module. The first is a deep learning based while the second is a Gaussian Process based approach. More details regarding the modeling are presented [**here**](https://rachitpras.github.io/UAV_autonomous_navigation/project/explanation/2021/11/25/Data-driven-Target-Tracking.html). The trajectory prediction of the dynamic obstacles and other obstacle information is passed on to the **motion planning module**, which generates a collision-free trajectory for the ego-vehicle to track. For fast, real-time implementation it is important to have a planner which is computationally efficient and robust at the same time. Keeping this in mind, an artificial potential field (APF) based planner was designed at first. However, while APF is computationally efficient, it fails at generating optimal and robust trajectories. Hence, a new hierarchical motion planner was created, coupled with the more robust and optimal A* path planner. The resulting architechture was much more computationally efficient compared to the vanilla A*. A detailed explanation of both the approaches are provided [**here**](https://rachitpras.github.io/UAV_autonomous_navigation/project/explanation/2021/11/27/Collision-free-Motion-Planning-for-small-UAS.html). Finally, the path generated by the planning module is tracked by the **trajectory tracking control module**. Two different control archtitectures (PID and MPC) were experimented for the controller, details for which can be seen [**here**](https://github.com/rachitpras/UAV_autonomous_navigation/blob/main/_posts/2021-11-28-Trajectory-tracking-control-for-Quadcopter.md).

Some simulated results for an example scenario are shown below. The animations are for the same scenario, but with different motion planners, the first being generated using the Artificial Potential Field method, while in the second animation, the path has been generated using the hierarchical planner made up of A* and Finite State Machine.   

<figure>
  <img src="https://github.com/rachitpras/UAV_autonomous_navigation/blob/main/images/2_drone_test_APF_3D.gif" alt="Autonomous UAV navigation using the APF planner" width="800"/> 
  <figcaption text-align = "center"><b>Autonomous UAV navigation using the APF planner.</b></figcaption>
</figure>

<figure>
  <img src="https://github.com/rachitpras/UAV_autonomous_navigation/blob/main/images/2_drone_test_BP_3D.gif" alt="Autonomous UAV navigation using the APF planner" width="800"/> 
  <figcaption text-align = "center"><b>Autonomous UAV navigation using the hierarchical planner.</b></figcaption>
</figure>

